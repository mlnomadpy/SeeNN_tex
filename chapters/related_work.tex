% \section{Related Work}



%%%%%%%%%%%%%%%%%%%%%


% \subsection{Deep Learning}
% \subsubsection{Multi-Layer Perceptron}
% \subsubsection{Convolution Neural Networks}
% \subsubsection{Transformers}
% \subsubsection{Multi-Layer Perceptron}
% \subsection{Multimodal Deep Learning}

% Many methods have been proposed in the literature that deals with fusing the different modalities and multiples stream network, ranging from simple concatenation of different inputs right from the get go, i.e. early fusion, feeding everything to a single feature extractor that extract as much information before feeding it to the either a decoder or a classifier head or a projection head.

% or having the different modalities first fed to a certain amount of layers before fusing all the extracted embeddings from each encoder layer, where the model learn to extract as many useful features from each modality before they get fused, where it deals with the limits of the early fusion methods where one modality dominate over the feature space ending up losing compute power without gaining any improvement in model's performance.

% The other type of fusion is the late fusion, where each modality is passed through it's own encoder, decoder, or any amount of layers until the decision layer (binary classification for example) than the fusion is done by either a vote between the different models or a mean of different decision taken.

% While each of these approach has it's own advantages and drawbacks, the amount of uncertainty of each method, and impact on the final decision they have, as well   
