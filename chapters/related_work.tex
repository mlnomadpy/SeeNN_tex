\section{Related Work}

In the literature, many methods have been proposed to fuse different modalities in multi-stream networks. These methods can be broadly categorized into early fusion, intermediate fusion, and late fusion.

\subsection{Early Fusion}
Early fusion involves concatenating different input modalities at the very beginning. The combined data is then fed into a single feature extractor, which learns to extract information from the fused representation. This approach is straightforward but can be limited if one modality dominates the feature space, leading to wasted computational resources without performance gains.

\subsection{Intermediate Fusion}
Intermediate fusion, also known as mid-level fusion, involves feeding each modality through a few layers of its own encoder before fusing the extracted embeddings. This allows the model to learn useful features from each modality before they are combined, addressing some of the limitations of early fusion.

\subsection{Late Fusion}
In late fusion, each modality is passed through its own complete encoder-decoder or classification network. The fusion occurs at the decision level, where the outputs from the different models are combined through methods like voting or averaging. While this approach allows for modality-specific processing, it may not fully exploit the correlations between modalities at earlier stages.

Each of these fusion strategies has its own advantages and disadvantages. The choice of fusion method can significantly impact the model's performance, and the optimal approach often depends on the specific application and the nature of the modalities being fused.
